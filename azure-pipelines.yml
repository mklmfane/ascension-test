trigger: none

variables:
  serviceConnection: 'terraform-access'
  GO_VERSION: '1.24.5'
  TFSEC_VERSION: 'v1.28.14'
  TFLINT_VERSION: 'v0.59.1'
  doDestroy: 'true'  # set to 'true' to enable destroy stage
  RG_NAME_PREFIX: 'ascension-up'
  location: 'northeurope'

stages:
# =====================================
# DEV STAGE (build -> infra -> apps)
# =====================================
- stage: dev
  displayName: 'DEV'
  variables: { env: 'dev' }
  jobs:
  # ---- dev_infra ----
  - job: dev_infra
    displayName: 'Provision infra (dev)'
    pool: { name: 'ubuntuvm' }
    steps:
      - checkout: self
        clean: true

      - task: AzureCLI@2
        displayName: 'Login + tools + plan/apply (dev)'
        inputs:
          azureSubscription: '$(serviceConnection)'
          scriptType: bash
          scriptLocation: inlineScript
          inlineScript: |
            set -euo pipefail
            az account show

            TF_DIR="$(Build.SourcesDirectory)/terraform"

            # --- Optional lint (kept minimal here) ---
            BIN_DIR="$(Agent.TempDirectory)/bin"; mkdir -p "$BIN_DIR"; export PATH="$BIN_DIR:$PATH"
            tflint --init && tflint --recursive || true
            tfsec "$TF_DIR" || true

            # --- Init + workspace (create only if missing) ---
            terraform -chdir="$TF_DIR" init -input=false
            ensure_ws() {
              local dir="$1" ws="$2"
              if terraform -chdir="$dir" workspace list | sed 's/*//;s/ //g' | grep -Fxq "$ws"; then
                terraform -chdir="$dir" workspace select "$ws"
              else
                terraform -chdir="$dir" workspace new "$ws"
              fi
            }
            ensure_ws "$TF_DIR" "$(env)"

            # --- Import-if-exists guard for Resource Group (idempotent) ---
            SUB_ID=$(az account show --query id -o tsv)
            RG_NAME="$(RG_NAME_PREFIX)-$(env)-rg"
            if az group exists -n "$RG_NAME"; then
              if ! terraform -chdir="$TF_DIR" state show azurerm_resource_group.ascension_test_rg >/dev/null 2>&1; then
                terraform -chdir="$TF_DIR" import azurerm_resource_group.ascension_test_rg "/subscriptions/$SUB_ID/resourceGroups/$RG_NAME" || true
              fi
            fi

            # --- Resolve pipeline principal object id you pass to TF ---
            SC_CLIENT_ID="331a5bcb-b95d-4529-a528-c858e28d9a89"
            PIPELINE_PRINCIPAL_OBJECT_ID=$(az ad sp show --id "$SC_CLIENT_ID" --query id -o tsv)

            # =========================================================
            # Phase 1: Targeted apply to create the Key Vault only
            # =========================================================
            echo ">>> Phase 1: apply target to create Key Vault"
            terraform -chdir="$TF_DIR" plan -no-color -input=false \
              -target=module.app_service.azurerm_key_vault.kv \
              -var="workflow=$(env)" \
              -var="pipeline_principal_id=$PIPELINE_PRINCIPAL_OBJECT_ID" \
              -out="tfplan.phase1.$(env).out"

            terraform -chdir="$TF_DIR" apply -auto-approve -no-color "tfplan.phase1.$(env).out"

            # Wait for KV to be queryable
            echo "Waiting for Key Vault to be queryable..."
            for i in {1..10}; do
              KV_ID=$(az keyvault list -g "$RG_NAME" \
                --query "[?starts_with(name, 'kv-$(env)-ascension-')].id | [0]" -o tsv 2>/dev/null || true)
              [ -n "$KV_ID" ] && break || sleep 6
            done
            if [ -z "${KV_ID:-}" ]; then
              echo "ERROR: Key Vault not found in resource group $RG_NAME after creation."; exit 1
            fi
            echo "KV_ID=$KV_ID"

            # =========================================================
            # Import-if-exists guards for KV role assignments
            # =========================================================
            TF_ADDR_SELF="module.app_service.azurerm_role_assignment.kv_secrets_officer_self"
            TF_ADDR_PIPE="module.app_service.azurerm_role_assignment.kv_secrets_officer_pipeline[0]"
            ROLE_NAME="Key Vault Secrets Officer"

            SELF_OBJECT_ID=$(az ad signed-in-user show --query id -o tsv 2>/dev/null || true)
            if [ -z "${SELF_OBJECT_ID:-}" ]; then
              SELF_OBJECT_ID=$(az ad sp show --id "$SC_CLIENT_ID" --query id -o tsv 2>/dev/null || true)
            fi

            if [ -n "${SELF_OBJECT_ID:-}" ]; then
              EXIST_SELF=$(az role assignment list \
                --assignee-object-id "$SELF_OBJECT_ID" \
                --scope "$KV_ID" \
                --role "$ROLE_NAME" \
                --query "[0].id" -o tsv || true)
              if [ -n "$EXIST_SELF" ]; then
                echo "Importing existing KV role assignment (self): $EXIST_SELF"
                terraform -chdir="$TF_DIR" import "$TF_ADDR_SELF" "$EXIST_SELF" || true
              fi
            fi

            if [ -n "${PIPELINE_PRINCIPAL_OBJECT_ID:-}" ] && [ "${PIPELINE_PRINCIPAL_OBJECT_ID}" != "null" ]; then
              EXIST_PIPE=$(az role assignment list \
                --assignee-object-id "$PIPELINE_PRINCIPAL_OBJECT_ID" \
                --scope "$KV_ID" \
                --role "$ROLE_NAME" \
                --query "[0].id" -o tsv || true)
              if [ -n "$EXIST_PIPE" ]; then
                echo "Importing existing KV role assignment (pipeline): $EXIST_PIPE"
                terraform -chdir="$TF_DIR" import "$TF_ADDR_PIPE" "$EXIST_PIPE" || true
              fi
            fi

            # =========================================================
            # Phase 2: Full plan/apply
            # =========================================================
            echo ">>> Phase 2: full plan/apply"
            terraform -chdir="$TF_DIR" plan -no-color -input=false \
              -var="workflow=$(env)" \
              -var="pipeline_principal_id=$PIPELINE_PRINCIPAL_OBJECT_ID" \
              -var="frontend_image_name=frontend-$(env)" \
              -var="frontend_image_tag=${BUILD_BUILDID}" \
              -out="tfplan.$(env).out"

            if [ "$(Build.SourceBranch)" = "refs/heads/main" ]; then
              terraform -chdir="$TF_DIR" apply -auto-approve -no-color "tfplan.$(env).out"
              terraform -chdir="$TF_DIR" output -json > "$TF_DIR/tf-outputs.$(env).json"
            else
              echo "Not main branch, skipping apply."
            fi

      - publish: $(Build.SourcesDirectory)/terraform/tf-outputs.$(env).json
        artifact: tf-outputs-$(env)
        condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
        displayName: 'Publish tf-outputs'

  # ---- dev_func_local_test ----
  - job: dev_func_local_test
    displayName: 'Azure Function local test (Python 3.11, no heredocs)'
    pool: { name: 'ubuntuvm' }
    steps:
      - checkout: self
        clean: true

      - bash: |
          set -e
          echo "whoami: $(whoami)"; id
          ls -l /var/run/docker.sock || true
          docker info >/dev/null
          docker version
        displayName: 'Verify Docker daemon access (self-hosted)'

      - bash: |
          set -e
          if command -v python3 >/dev/null 2>&1; then
            PY="$(command -v python3)"
          else
            echo "No python3 installed on the agent." >&2
            exit 1
          fi
          echo "Using Python: $PY"
          "$PY" --version
          echo "##vso[task.setvariable variable=PY]$PY"
        displayName: 'Resolve Python (prefer 3.11)'

      - task: NodeTool@0
        inputs:
          versionSpec: '18.x'
        displayName: 'Use Node 18.x'

      - bash: |
          set -e
          mkdir -p "$HOME/.npm-global"
          npm config set prefix "$HOME/.npm-global"
          export PATH="$HOME/.npm-global/bin:$PATH"
          echo 'export PATH="$HOME/.npm-global/bin:$PATH"' >> ~/.bashrc
          # npm retry knobs to survive transient network hiccups
          export npm_config_fetch_retries=6
          export npm_config_fetch_retry_factor=2
          export npm_config_fetch_retry_maxtimeout=120000
          export npm_config_network_timeout=120000
          n=0
          until [ $n -ge 5 ]; do
            npm i -g azure-functions-core-tools@4 --unsafe-perm true && break
            n=$((n+1)); echo "retry $n/5…"; sleep $((5*n))
          done
          func --version
        displayName: 'Install Azure Functions Core Tools v4 (user)'

      - bash: |
          set -euo pipefail
          export PATH="$HOME/.npm-global/bin:$PATH"
          cd "$(Build.SourcesDirectory)/api-function"

          # venv + deps (quiet, no pip self-upgrade)
          "$PY" -m venv .venv
          . .venv/bin/activate
          export PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install -q -r requirements.txt

          # Imports for package layout
          export PYTHONPATH="$(pwd):${PYTHONPATH:-}"

          # settings from repo; normalize worker runtime for local host
          cp -f local.settings.example.json local.settings.json
          sed -E -i 's/("FUNCTIONS_WORKER_RUNTIME":)[[:space:]]*"[^"]+"/\1 "python"/' local.settings.json

          # start host
          LOG_FILE="$(Build.SourcesDirectory)/.func.log"
          PID_FILE="$(Build.SourcesDirectory)/.func.pid"
          nohup func start --python3 --port 7071 --verbose > "$LOG_FILE" 2>&1 & echo $! > "$PID_FILE"

          echo "Waiting for Functions host..."
          ready=0
          for i in {1..90}; do
            if curl -fsS "http://127.0.0.1:7071/admin/host/status" >/dev/null 2>&1; then ready=1; break; fi
            if grep -qE 'Host started|Job host started' "$LOG_FILE" 2>/dev/null; then ready=1; break; fi
            sleep 2
          done

          if [ "$ready" -ne 1 ]; then
            echo "ERROR: Host not ready. Last 200 log lines:" >&2
            tail -n 200 "$LOG_FILE" || true
            kill "$(cat "$PID_FILE")" 2>/dev/null || true
            pkill -f "func start" || true
            exit 1
          fi

          echo "Smoke test /api/products:"
          curl -v "http://127.0.0.1:7071/api/products" || true

          echo "Running pytest…"
          pytest -q
        displayName: 'Create venv, normalize settings, start func, smoke-test, pytest'

      - bash: |
          set -euo pipefail
          PID_FILE="$(Build.SourcesDirectory)/.func.pid"
          LOG_FILE="$(Build.SourcesDirectory)/.func.log"
          if [ -f "$PID_FILE" ]; then
            echo "Stopping Functions host (PID $(cat "$PID_FILE")) ..."
            kill "$(cat "$PID_FILE")" || true
            pkill -f "func start" || true
            sleep 2
          fi
          echo "Last 200 lines of Functions host log:"
          tail -n 200 "$LOG_FILE" || true
        displayName: 'Stop func & show logs'
        condition: always()

  # ---- build_dev ----
  - job: build_dev
    displayName: 'Build frontend for React with App Service & package function (dev)'
    dependsOn:
      - dev_infra
      - dev_func_local_test
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    pool: { name: 'ubuntuvm' }
    steps:
      - checkout: self
        clean: true

      # Download TF outputs produced by dev_infra (main only)
      - download: current
        artifact: tf-outputs-$(env)
        displayName: 'Download tf outputs'

      - task: AzureCLI@2
        displayName: 'Login + Build & Push Frontend Container to ACR'
        inputs:
          azureSubscription: '$(serviceConnection)'
          scriptType: bash
          scriptLocation: inlineScript
          inlineScript: |
            set -euo pipefail

            TF_OUT="$(Pipeline.Workspace)/tf-outputs-$(env)/tf-outputs.$(env).json"

            # Derive RG from your pipeline vars (avoids JSON parsing altogether)
            RG_NAME="${RG_NAME_PREFIX}-$(env)-rg"

            echo "Resource Group will be assumed as: ${RG_NAME}"
            echo "If present, will also try to read ACR details from: ${TF_OUT}"

            ACR_LOGIN_SERVER=""

            # 1) Best-effort: read acr_login_server from the TF outputs JSON using grep/sed (no python/jq)
            if [ -s "$TF_OUT" ]; then
              # pull: "acr_login_server": {"value":"X.azurecr.io", ...}
              ACR_LOGIN_SERVER="$(grep -oP '"acr_login_server"\s*:\s*\{[^}]*\}' "$TF_OUT" 2>/dev/null \
              | grep -oP '"value"\s*:\s*"\K[^"]+' 2>/dev/null || true)"
            if [ -n "${ACR_LOGIN_SERVER}" ]; then
              echo "Found acr_login_server in TF outputs: ${ACR_LOGIN_SERVER}"
            else
              # try via acr_name -> az show
              ACR_NAME_FROM_OUT="$(grep -oP '"acr_name"\s*:\s*\{[^}]*\}' "$TF_OUT" 2>/dev/null \
              | grep -oP '"value"\s*:\s*"\K[^"]+' 2>/dev/null || true)"
              if [ -n "${ACR_NAME_FROM_OUT}" ]; then
                echo "Found acr_name in TF outputs: ${ACR_NAME_FROM_OUT}. Resolving loginServer via az..."
                ACR_LOGIN_SERVER="$(az acr show -g "$RG_NAME" -n "$ACR_NAME_FROM_OUT" --query loginServer -o tsv 2>/dev/null || true)"
              fi
            fi
            else
              echo "TF outputs file missing or empty (ok, will discover via Azure): $TF_OUT"
            fi

            # 2) Discovery fallback via Azure (RG must already exist in your subscription)
            if [ -z "${ACR_LOGIN_SERVER}" ]; then
              echo "Discovering ACR in RG '${RG_NAME}'..."
              mapfile -t SERVERS < <(az acr list -g "$RG_NAME" --query "[].loginServer" -o tsv)
              if [ "${#SERVERS[@]}" -eq 0 ]; then
                echo "ERROR: No ACR found in resource group '${RG_NAME}', and no TF outputs provided."
                echo "Diagnostics: az acr list -g '${RG_NAME}' --output table"
                az acr list -g "$RG_NAME" --output table || true
                exit 1
              fi

            if [ "${#SERVERS[@]}" -gt 1 ]; then
              echo "WARNING: Multiple ACRs found in RG '${RG_NAME}'. Using the first one:"
              printf ' - %s\n' "${SERVERS[@]}"
            fi
              ACR_LOGIN_SERVER="${SERVERS[0]}"
            fi

            test -n "${ACR_LOGIN_SERVER}" || { echo "Could not resolve ACR login server"; exit 1; }
            ACR_NAME="${ACR_LOGIN_SERVER%%.*}"
            echo "Using ACR: ${ACR_NAME} (${ACR_LOGIN_SERVER})"

            # Ensure Docker is available
            if ! command -v docker >/dev/null 2>&1; then
              echo "Docker not found on agent. Please install & start Docker on 'ubuntuvm'." >&2
              exit 1
            fi

            # Login to ACR
            az acr login -n "${ACR_NAME}"

            # Build & push
            FRONTEND_DIR="$(Build.SourcesDirectory)/react-frontend-image"
            test -f "$FRONTEND_DIR/Dockerfile" || { echo "frontend/Dockerfile not found"; exit 1; }
            test -f "$FRONTEND_DIR/nginx.conf" || { echo "frontend/nginx.conf not found"; exit 1; }

            IMG_NAME="frontend-$(env)"
            IMG_TAG="$(Build.BuildId)"
            IMAGE_URI="${ACR_LOGIN_SERVER}/${IMG_NAME}:${IMG_TAG}"

            echo "Building ${IMAGE_URI} from ${FRONTEND_DIR}"
            docker build -t "${IMAGE_URI}" "${FRONTEND_DIR}"
            docker push "${IMAGE_URI}"

            # Save metadata for the deploy stage
            META_DIR="$(Build.ArtifactStagingDirectory)/react-frontend-image"
            mkdir -p "$META_DIR"
            cat > "$META_DIR/image.json" <<EOF
            {
              "acr_login_server": "${ACR_LOGIN_SERVER}",
              "image_name": "${IMG_NAME}",
              "image_tag": "${IMG_TAG}",
              "image_uri": "${IMAGE_URI}"
            }
            EOF
            
      - publish: $(Build.ArtifactStagingDirectory)/react-frontend-image
        artifact: react-frontend-image

      # Package Python Azure Function (zip) from api-function/
      - bash: |
          set -euo pipefail
          FUNC_SRC="$(Build.SourcesDirectory)/api-function"
          OUT_DIR="$(Build.ArtifactStagingDirectory)/function"
          mkdir -p "$OUT_DIR"

          test -f "$FUNC_SRC/host.json" || { echo "api-function/host.json missing"; exit 1; }

          python3 -m pip install --upgrade pip
          python3 -m pip install -r "$FUNC_SRC/requirements.txt" --target "$FUNC_SRC/.python_packages/lib/site-packages"

          cd "$FUNC_SRC"
          zip -r "$OUT_DIR/function.zip" . \
            -x ".*" -x "__pycache__/*" -x ".venv/*" -x "venv/*" >/dev/null
          echo "Created $OUT_DIR/function.zip"
        displayName: 'Package Python Azure Function (zip)'

      # Publish the folder that contains function.zip, name the artifact "function"
      - publish: $(Build.ArtifactStagingDirectory)/function
        artifact: function

  # ---- dev_apps ----
  - job: deploy_apps
    displayName: 'Deploy apps (dev)'
    dependsOn: [ build_dev ]
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    pool: { name: 'ubuntuvm' }
    steps:
      - download: current
        artifact: react-frontend-image
      - download: current
        artifact: function
      - download: current
        artifact: tf-outputs-$(env)

      - task: AzureCLI@2
        displayName: 'Point Web App to ACR image (Linux) + Deploy Function Zip'
        inputs:
          azureSubscription: '$(serviceConnection)'
          scriptType: bash
          scriptLocation: inlineScript
          inlineScript: |
            set -euo pipefail

            TF_OUT="$(Pipeline.Workspace)/tf-outputs-$(env)/tf-outputs.$(env).json"
            IMG_META="$(Pipeline.Workspace)/frontend-image/image.json"
            FN_ZIP="$(Pipeline.Workspace)/function/function.zip"

            test -f "$TF_OUT"   || { echo "Missing TF outputs $TF_OUT"; exit 1; }
            test -f "$IMG_META" || { echo "Missing image metadata $IMG_META"; exit 1; }
            test -f "$FN_ZIP"   || { echo "Function zip not found at $FN_ZIP"; exit 1; }

            RG=$(python3 -c "import json,sys;print(json.load(open(sys.argv[1]))['resource_group_name']['value'])" "$TF_OUT")
            WEB=$(python3 -c "import json,sys;print(json.load(open(sys.argv[1]))['react_web_name']['value'])" "$TF_OUT")
            FN=$(python3 -c "import json,sys;print(json.load(open(sys.argv[1]))['function_name']['value'])" "$TF_OUT")
            ACR_LOGIN_SERVER=$(python3 -c "import json,sys;print(json.load(open(sys.argv[1]))['acr_login_server'])" "$IMG_META")
            IMAGE_URI=$(python3 -c "import json,sys;print(json.load(open(sys.argv[1]))['image_uri'])" "$IMG_META")

            echo "RG=$RG WEB=$WEB FN=$FN"
            echo "IMAGE_URI=$IMAGE_URI"

            KIND=$(az webapp show -g "$RG" -n "$WEB" --query "kind" -o tsv)
            RESERVED=$(az webapp show -g "$RG" -n "$WEB" --query "reserved" -o tsv)
            if [[ "${RESERVED}" != "true" && "${KIND}" != *"linux"* ]]; then
              echo "ERROR: Web App '$WEB' is not Linux."; exit 1
            fi

            az webapp config container set \
              -g "$RG" -n "$WEB" \
              --docker-custom-image-name "$IMAGE_URI" \
              --docker-registry-server-url "https://${ACR_LOGIN_SERVER}" || true

            az webapp config set -g "$RG" -n "$WEB" --acr-use-managed-identity
            az webapp config appsettings set -g "$RG" -n "$WEB" --settings \
              WEBSITES_ENABLE_APP_SERVICE_STORAGE=false \
              WEBSITES_PORT=80
            az webapp restart -g "$RG" -n "$WEB"

            az functionapp config appsettings set -g "$RG" -n "$FN" --settings SCM_DO_BUILD_DURING_DEPLOYMENT=true
            az functionapp deployment source config-zip -g "$RG" -n "$FN" --src "$FN_ZIP"

            curl -fsS "https://${FN}.azurewebsites.net/api/products" || true

# ===== Optional destroy (linear after dev) =====
- stage: destroy
  displayName: 'Terraform destroy (guarded)'
  dependsOn: dev
  condition: and(succeeded(), eq(variables['doDestroy'], 'true'))
  jobs:
  - job: destroy_all
    pool: { name: 'ubuntuvm' }
    strategy:
      matrix:
        dev: { env: dev }
    steps:
      - checkout: self
        clean: true
      - task: AzureCLI@2
        displayName: "Destroy $(env)"
        inputs:
          azureSubscription: '$(serviceConnection)'
          scriptType: bash
          scriptLocation: inlineScript
          inlineScript: |
            set -euo pipefail
            terraform -chdir="$(Build.SourcesDirectory)/terraform" init -input=false
            terraform -chdir="$(Build.SourcesDirectory)/terraform" workspace select -or-create "$(env)"
            terraform -chdir="$(Build.SourcesDirectory)/terraform" destroy -no-color -auto-approve -var="workflow=$(env)"
