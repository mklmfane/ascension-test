trigger: none

variables:
  serviceConnection: 'terraform-access'
  GO_VERSION: '1.24.5'
  TFSEC_VERSION: 'v1.28.14'
  TFLINT_VERSION: 'v0.59.1'
  doDestroy: 'true'  # set to 'true' to enable destroy stage
  RG_NAME_PREFIX: 'ascension-up'
  location: 'northeurope'

stages:
# =====================================
# DEV STAGE (build -> infra -> apps)
# =====================================
- stage: dev
  displayName: 'DEV'
  variables: { env: 'dev' }
  jobs:
  # ---- dev_infra ----
  - job: dev_infra
    displayName: 'Provision infra (dev)'
    pool: { name: 'ubuntuvm' }
    steps:
      - checkout: self
        clean: true

      - task: AzureCLI@2
        displayName: 'Login + tools + plan/apply (dev)'
        inputs:
          azureSubscription: '$(serviceConnection)'
          scriptType: bash
          scriptLocation: inlineScript
          inlineScript: |
            set -euo pipefail
            az account show

            TF_DIR="$(Build.SourcesDirectory)/terraform"

            # --- Optional lint (kept minimal here) ---
            BIN_DIR="$(Agent.TempDirectory)/bin"; mkdir -p "$BIN_DIR"; export PATH="$BIN_DIR:$PATH"
            tflint --init && tflint --recursive || true
            tfsec "$TF_DIR" || true

            # --- Init + workspace (create only if missing) ---
            terraform -chdir="$TF_DIR" init -input=false
            ensure_ws() {
              local dir="$1" ws="$2"
              if terraform -chdir="$dir" workspace list | sed 's/*//;s/ //g' | grep -Fxq "$ws"; then
                terraform -chdir="$dir" workspace select "$ws"
              else
                terraform -chdir="$dir" workspace new "$ws"
              fi
            }
            ensure_ws "$TF_DIR" "$(env)"

            # --- Import-if-exists guard for Resource Group (idempotent) ---
            SUB_ID=$(az account show --query id -o tsv)
            RG_NAME="$(RG_NAME_PREFIX)-$(env)-rg"
            if az group exists -n "$RG_NAME"; then
              if ! terraform -chdir="$TF_DIR" state show azurerm_resource_group.ascension_test_rg >/dev/null 2>&1; then
                terraform -chdir="$TF_DIR" import azurerm_resource_group.ascension_test_rg "/subscriptions/$SUB_ID/resourceGroups/$RG_NAME" || true
              fi
            fi

            # --- Resolve pipeline principal object id you pass to TF ---
            SC_CLIENT_ID="331a5bcb-b95d-4529-a528-c858e28d9a89"
            PIPELINE_PRINCIPAL_OBJECT_ID=$(az ad sp show --id "$SC_CLIENT_ID" --query id -o tsv)

            # =========================================================
            # Phase 1: Targeted apply to create the Key Vault only
            # =========================================================
            echo ">>> Phase 1: apply target to create Key Vault"
            terraform -chdir="$TF_DIR" plan -no-color -input=false \
              -target=module.app_service.azurerm_key_vault.kv \
              -var="workflow=$(env)" \
              -var="pipeline_principal_id=$PIPELINE_PRINCIPAL_OBJECT_ID" \
              -out="tfplan.phase1.$(env).out"

            terraform -chdir="$TF_DIR" apply -auto-approve -no-color "tfplan.phase1.$(env).out"

            # Wait for KV to be queryable
            echo "Waiting for Key Vault to be queryable..."
            for i in {1..10}; do
              KV_ID=$(az keyvault list -g "$RG_NAME" \
                --query "[?starts_with(name, 'kv-$(env)-ascension-')].id | [0]" -o tsv 2>/dev/null || true)
              [ -n "$KV_ID" ] && break || sleep 6
            done
            if [ -z "${KV_ID:-}" ]; then
              echo "ERROR: Key Vault not found in resource group $RG_NAME after creation."; exit 1
            fi
            echo "KV_ID=$KV_ID"

            # =========================================================
            # Import-if-exists guards for KV role assignments
            # =========================================================
            TF_ADDR_SELF="module.app_service.azurerm_role_assignment.kv_secrets_officer_self"
            TF_ADDR_PIPE="module.app_service.azurerm_role_assignment.kv_secrets_officer_pipeline[0]"
            ROLE_NAME="Key Vault Secrets Officer"

            SELF_OBJECT_ID=$(az ad signed-in-user show --query id -o tsv 2>/dev/null || true)
            if [ -z "${SELF_OBJECT_ID:-}" ]; then
              SELF_OBJECT_ID=$(az ad sp show --id "$SC_CLIENT_ID" --query id -o tsv 2>/dev/null || true)
            fi

            if [ -n "${SELF_OBJECT_ID:-}" ]; then
              EXIST_SELF=$(az role assignment list \
                --assignee-object-id "$SELF_OBJECT_ID" \
                --scope "$KV_ID" \
                --role "$ROLE_NAME" \
                --query "[0].id" -o tsv || true)
              if [ -n "$EXIST_SELF" ]; then
                echo "Importing existing KV role assignment (self): $EXIST_SELF"
                terraform -chdir="$TF_DIR" import "$TF_ADDR_SELF" "$EXIST_SELF" || true
              fi
            fi

            if [ -n "${PIPELINE_PRINCIPAL_OBJECT_ID:-}" ] && [ "${PIPELINE_PRINCIPAL_OBJECT_ID}" != "null" ]; then
              EXIST_PIPE=$(az role assignment list \
                --assignee-object-id "$PIPELINE_PRINCIPAL_OBJECT_ID" \
                --scope "$KV_ID" \
                --role "$ROLE_NAME" \
                --query "[0].id" -o tsv || true)
              if [ -n "$EXIST_PIPE" ]; then
                echo "Importing existing KV role assignment (pipeline): $EXIST_PIPE"
                terraform -chdir="$TF_DIR" import "$TF_ADDR_PIPE" "$EXIST_PIPE" || true
              fi
            fi

            # =========================================================
            # Phase 2: Full plan/apply
            # =========================================================
            echo ">>> Phase 2: full plan/apply"
            terraform -chdir="$TF_DIR" plan -no-color -input=false \
              -var="workflow=$(env)" \
              -var="pipeline_principal_id=$PIPELINE_PRINCIPAL_OBJECT_ID" \
              -var="frontend_image_name=frontend-$(env)" \
              -var="frontend_image_tag=${BUILD_BUILDID}" \
              -out="tfplan.$(env).out"

            if [ "$(Build.SourceBranch)" = "refs/heads/main" ]; then
              terraform -chdir="$TF_DIR" apply -auto-approve -no-color "tfplan.$(env).out"
              terraform -chdir="$TF_DIR" output -json > "$TF_DIR/tf-outputs.$(env).json"
            else
              echo "Not main branch, skipping apply."
            fi

      - publish: $(Build.SourcesDirectory)/terraform/tf-outputs.$(env).json
        artifact: tf-outputs-$(env)
        condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
        displayName: 'Publish tf-outputs'

  # ---- dev_func_local_test ----
  - job: dev_func_local_test
    displayName: 'Azure Function local test (Python 3.11, no heredocs)'
    pool: { name: 'ubuntuvm' }
    steps:
      - checkout: self
        clean: true

      - bash: |
          set -e
          echo "whoami: $(whoami)"; id
          ls -l /var/run/docker.sock || true
          docker info >/dev/null
          docker version
        displayName: 'Verify Docker daemon access (self-hosted)'

      - bash: |
          set -e
          if command -v python3 >/dev/null 2>&1; then
            PY="$(command -v python3)"
          else
            echo "No python3 installed on the agent." >&2
            exit 1
          fi
          echo "Using Python: $PY"
          "$PY" --version
          echo "##vso[task.setvariable variable=PY]$PY"
        displayName: 'Resolve Python (prefer 3.11)'

      - task: NodeTool@0
        inputs:
          versionSpec: '18.x'
        displayName: 'Use Node 18.x'

      - bash: |
          set -e
          mkdir -p "$HOME/.npm-global"
          npm config set prefix "$HOME/.npm-global"
          export PATH="$HOME/.npm-global/bin:$PATH"
          echo 'export PATH="$HOME/.npm-global/bin:$PATH"' >> ~/.bashrc
          # npm retry knobs to survive transient network hiccups
          export npm_config_fetch_retries=6
          export npm_config_fetch_retry_factor=2
          export npm_config_fetch_retry_maxtimeout=120000
          export npm_config_network_timeout=120000
          n=0
          until [ $n -ge 5 ]; do
            npm i -g azure-functions-core-tools@4 --unsafe-perm true && break
            n=$((n+1)); echo "retry $n/5…"; sleep $((5*n))
          done
          func --version
        displayName: 'Install Azure Functions Core Tools v4 (user)'

      - bash: |
          set -euo pipefail
          export PATH="$HOME/.npm-global/bin:$PATH"
          cd "$(Build.SourcesDirectory)/api-function"

          # venv + deps (quiet, no pip self-upgrade)
          "$PY" -m venv .venv
          . .venv/bin/activate
          export PIP_DISABLE_PIP_VERSION_CHECK=1
          python3 -m pip install -q -r requirements.txt

          # Imports for package layout
          export PYTHONPATH="$(pwd):${PYTHONPATH:-}"

          # settings from repo; normalize worker runtime for local host
          cp -f local.settings.example.json local.settings.json
          sed -E -i 's/("FUNCTIONS_WORKER_RUNTIME":)[[:space:]]*"[^"]+"/\1 "python"/' local.settings.json

          # start host
          LOG_FILE="$(Build.SourcesDirectory)/.func.log"
          PID_FILE="$(Build.SourcesDirectory)/.func.pid"
          nohup func start --python3 --port 7071 --verbose > "$LOG_FILE" 2>&1 & echo $! > "$PID_FILE"

          echo "Waiting for Functions host..."
          ready=0
          for i in {1..90}; do
            if curl -fsS "http://127.0.0.1:7071/admin/host/status" >/dev/null 2>&1; then ready=1; break; fi
            if grep -qE 'Host started|Job host started' "$LOG_FILE" 2>/dev/null; then ready=1; break; fi
            sleep 2
          done

          if [ "$ready" -ne 1 ]; then
            echo "ERROR: Host not ready. Last 200 log lines:" >&2
            tail -n 200 "$LOG_FILE" || true
            kill "$(cat "$PID_FILE")" 2>/dev/null || true
            pkill -f "func start" || true
            exit 1
          fi

          echo "Smoke test /api/products:"
          curl -v "http://127.0.0.1:7071/api/products" || true

          echo "Running pytest…"
          pytest -q
        displayName: 'Create venv, normalize settings, start func, smoke-test, pytest'

      - bash: |
          set -euo pipefail
          PID_FILE="$(Build.SourcesDirectory)/.func.pid"
          LOG_FILE="$(Build.SourcesDirectory)/.func.log"
          if [ -f "$PID_FILE" ]; then
            echo "Stopping Functions host (PID $(cat "$PID_FILE")) ..."
            kill "$(cat "$PID_FILE")" || true
            pkill -f "func start" || true
            sleep 2
          fi
          echo "Last 200 lines of Functions host log:"
          tail -n 200 "$LOG_FILE" || true
        displayName: 'Stop func & show logs'
        condition: always()

  # ---- build_dev ----
  - job: build_dev
    displayName: 'Build frontend for React with App Service & package function (dev)'
    dependsOn:
      - dev_infra
      - dev_func_local_test
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    pool: { name: 'ubuntuvm' }
    steps:
      - checkout: self
        clean: true

      # Download TF outputs produced by dev_infra (main only)
      - download: current
        artifact: tf-outputs-$(env)
        displayName: 'Download tf outputs'

      - task: AzureCLI@2
        displayName: 'Login + Build & Push Frontend Container to ACR'
        inputs:
          azureSubscription: '$(serviceConnection)'
          scriptType: bash
          scriptLocation: inlineScript
          inlineScript: |
            set -euo pipefail

            TF_OUT="$(Pipeline.Workspace)/tf-outputs-$(env)/tf-outputs.$(env).json"

            # Derive RG from your pipeline vars (avoids JSON parsing altogether)
            RG_NAME="${RG_NAME_PREFIX}-$(env)-rg"

            echo "Resource Group will be assumed as: ${RG_NAME}"
            echo "If present, will also try to read ACR details from: ${TF_OUT}"

            ACR_LOGIN_SERVER=""

            # 1) Best-effort: read acr_login_server from the TF outputs JSON using grep/sed (no python/jq)
            if [ -s "$TF_OUT" ]; then
              # pull: "acr_login_server": {"value":"X.azurecr.io", ...}
              ACR_LOGIN_SERVER="$(grep -oP '"acr_login_server"\s*:\s*\{[^}]*\}' "$TF_OUT" 2>/dev/null \
              | grep -oP '"value"\s*:\s*"\K[^"]+' 2>/dev/null || true)"
            if [ -n "${ACR_LOGIN_SERVER}" ]; then
              echo "Found acr_login_server in TF outputs: ${ACR_LOGIN_SERVER}"
            else
              # try via acr_name -> az show
              ACR_NAME_FROM_OUT="$(grep -oP '"acr_name"\s*:\s*\{[^}]*\}' "$TF_OUT" 2>/dev/null \
              | grep -oP '"value"\s*:\s*"\K[^"]+' 2>/dev/null || true)"
              if [ -n "${ACR_NAME_FROM_OUT}" ]; then
                echo "Found acr_name in TF outputs: ${ACR_NAME_FROM_OUT}. Resolving loginServer via az..."
                ACR_LOGIN_SERVER="$(az acr show -g "$RG_NAME" -n "$ACR_NAME_FROM_OUT" --query loginServer -o tsv 2>/dev/null || true)"
              fi
            fi
            else
              echo "TF outputs file missing or empty (ok, will discover via Azure): $TF_OUT"
            fi

            # 2) Discovery fallback via Azure (RG must already exist in your subscription)
            if [ -z "${ACR_LOGIN_SERVER}" ]; then
              echo "Discovering ACR in RG '${RG_NAME}'..."
              mapfile -t SERVERS < <(az acr list -g "$RG_NAME" --query "[].loginServer" -o tsv)
              if [ "${#SERVERS[@]}" -eq 0 ]; then
                echo "ERROR: No ACR found in resource group '${RG_NAME}', and no TF outputs provided."
                echo "Diagnostics: az acr list -g '${RG_NAME}' --output table"
                az acr list -g "$RG_NAME" --output table || true
                exit 1
              fi

            if [ "${#SERVERS[@]}" -gt 1 ]; then
              echo "WARNING: Multiple ACRs found in RG '${RG_NAME}'. Using the first one:"
              printf ' - %s\n' "${SERVERS[@]}"
            fi
              ACR_LOGIN_SERVER="${SERVERS[0]}"
            fi

            test -n "${ACR_LOGIN_SERVER}" || { echo "Could not resolve ACR login server"; exit 1; }
            ACR_NAME="${ACR_LOGIN_SERVER%%.*}"
            echo "Using ACR: ${ACR_NAME} (${ACR_LOGIN_SERVER})"

            # Ensure Docker is available
            if ! command -v docker >/dev/null 2>&1; then
              echo "Docker not found on agent. Please install & start Docker on 'ubuntuvm'." >&2
              exit 1
            fi

            # Login to ACR
            az acr login -n "${ACR_NAME}"

            # Build & push
            FRONTEND_DIR="$(Build.SourcesDirectory)/react-frontend-image"
            test -f "$FRONTEND_DIR/Dockerfile" || { echo "frontend/Dockerfile not found"; exit 1; }
            test -f "$FRONTEND_DIR/nginx.conf" || { echo "frontend/nginx.conf not found"; exit 1; }

            IMG_NAME="frontend-$(env)"
            IMG_TAG="$(Build.BuildId)"
            IMAGE_URI="${ACR_LOGIN_SERVER}/${IMG_NAME}:${IMG_TAG}"

            echo "Building ${IMAGE_URI} from ${FRONTEND_DIR}"
            docker build -t "${IMAGE_URI}" "${FRONTEND_DIR}"
            docker push "${IMAGE_URI}"

            # Save metadata for the deploy stage
            META_DIR="$(Build.ArtifactStagingDirectory)/react-frontend-image"
            mkdir -p "$META_DIR"
            cat > "$META_DIR/image.json" <<EOF
            {
              "acr_login_server": "${ACR_LOGIN_SERVER}",
              "image_name": "${IMG_NAME}",
              "image_tag": "${IMG_TAG}",
              "image_uri": "${IMAGE_URI}"
            }
            EOF
            
      - publish: $(Build.ArtifactStagingDirectory)/react-frontend-image
        artifact: react-frontend-image

      # Package Python Azure Function (zip) from api-function/
      - bash: |
          set -euo pipefail

          FUNC_SRC="$(Build.SourcesDirectory)/api-function"
          OUT_DIR="$(Build.ArtifactStagingDirectory)/function"
          mkdir -p "$OUT_DIR"

          test -f "$FUNC_SRC/host.json" || { echo "api-function/host.json missing"; exit 1; }

          # --- create & use a venv (avoid PEP 668 system protection) ---
          VENV_DIR="$(Agent.TempDirectory)/func-venv"
          python3 -m venv "$VENV_DIR"
          . "$VENV_DIR/bin/activate"

          # be quiet & fast; no system breakages
          export PIP_DISABLE_PIP_VERSION_CHECK=1
          export PIP_NO_PYTHON_VERSION_WARNING=1

          # vendor dependencies into the expected Azure Functions path
          TARGET_DIR="$FUNC_SRC/.python_packages/lib/site-packages"
          mkdir -p "$TARGET_DIR"
          python3 -m pip install --upgrade pip wheel >/dev/null
          python3 -m pip install -r "$FUNC_SRC/requirements.txt" --target "$TARGET_DIR"

          # clean up pyc etc. (optional)
          find "$FUNC_SRC" -type f -name '*.pyc' -delete || true
          find "$FUNC_SRC" -type d -name '__pycache__' -prune -exec rm -rf {} + || true

          # create deployment zip (include .python_packages; exclude venv/git/cache)
          cd "$FUNC_SRC"
          zip -r "$OUT_DIR/function.zip" . \
            -x ".git/*" -x ".venv/*" -x "venv/*" -x "$(basename "$VENV_DIR")/*" \
            -x "__pycache__/*" >/dev/null

          echo "Created $OUT_DIR/function.zip"
        displayName: 'Build zip with python source for Azure Function'

      # Publish the folder that contains function.zip, name the artifact "function"
      - publish: $(Build.ArtifactStagingDirectory)/function
        artifact: function

# ---- dev_apps ----
  - job: deploy_apps
    displayName: 'Deploy apps (dev)'
    dependsOn: [ build_dev ]
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    pool: { name: 'ubuntuvm' }

    steps:
    # Bring in artifacts created in build_dev
      - download: current
        artifact: react-frontend-image
        displayName: 'Download frontend image metadata'
      - download: current
        artifact: function
        displayName: 'Download zip package for azure function'
      - download: current
        artifact: tf-outputs-$(env)
        displayName: 'Download tf outputs reading state'

    # Resolve RG, Web App, and Function App names (prefer TF outputs, fallback to live Azure)
      - task: AzureCLI@2
        displayName: 'Resolve RG / app names from TF outputs or Azure'
        inputs:
          azureSubscription: '$(serviceConnection)'
          scriptType: bash
          scriptLocation: inlineScript
          inlineScript: |
            set -euo pipefail

            TF_OUT="$(Pipeline.Workspace)/tf-outputs-$(env)/tf-outputs.$(env).json"

            # 1) Resolve resource group
            if [ -s "$TF_OUT" ] && command -v jq >/dev/null 2>&1; then
              RG="$(jq -r '.resource_group_name.value // .resource_group_name // empty' "$TF_OUT")"
            fi
            RG="${RG:-$(echo "$(RG_NAME_PREFIX)-$(env)-rg")}"

            # 2) Try to read names from TF outputs
            if [ -s "$TF_OUT" ] && command -v jq >/dev/null 2>&1; then
              WEB_NAME="$(jq -r '.react_web_name.value // .react_web_name // empty' "$TF_OUT")"
              FUNC_NAME="$(jq -r '.function_name.value // .function_name // empty' "$TF_OUT")"
            fi

            # 3) Fallback: discover in Azure
            if [ -z "${WEB_NAME:-}" ]; then
              # Prefer Linux Web Apps
              WEB_NAME="$(az webapp list -g "$RG" --query "[?contains(kind, 'linux')].name | [0]" -o tsv || true)"
            fi

            if [ -z "${FUNC_NAME:-}" ]; then
              # Prefer Linux Function Apps
              FUNC_NAME="$(az functionapp list -g "$RG" --query "[?contains(kind, 'functionapp,linux')].name | [0]" -o tsv || true)"
              # fallback to any functionapp
              if [ -z "$FUNC_NAME" ]; then
                FUNC_NAME="$(az functionapp list -g "$RG" --query "[0].name" -o tsv || true)"
              fi
            fi

            echo "Resolved: RG=$RG WEB_NAME=${WEB_NAME:-<none>} FUNC_NAME=${FUNC_NAME:-<none>}"

            # Guard rails: fail early with a helpful message
            if [ -z "${WEB_NAME:-}" ]; then
              echo "ERROR: Could not find a Linux Web App in resource group '$RG'."
              echo "Tip: ensure Terraform applied on 'main' and created the Web App."
              az webapp list -g "$RG" -o table || true
              exit 2
            fi
            if [ -z "${FUNC_NAME:-}" ]; then
              echo "ERROR: Could not find a Function App in resource group '$RG'."
              az functionapp list -g "$RG" -o table || true
              exit 3
            fi

            # Export variables for later tasks
            echo "##vso[task.setvariable variable=RG]$RG"
            echo "##vso[task.setvariable variable=WEB_NAME]$WEB_NAME"
            echo "##vso[task.setvariable variable=FUNC_NAME]$FUNC_NAME"

      # Read container image URI from artifact
      - bash: |
          set -euo pipefail
          META="$(Pipeline.Workspace)/react-frontend-image/image.json"
          if [ ! -s "$META" ]; then
            echo "ERROR: image.json not found at $META"; exit 1
          fi
          if command -v jq >/dev/null 2>&1; then
            IMAGE_URI="$(jq -r '.image_uri // empty' "$META")"
          else
            IMAGE_URI="$(grep -oP '"image_uri"\s*:\s*"\K[^"]+' "$META" || true)"
          fi
          if [ -z "${IMAGE_URI:-}" ]; then
            echo "ERROR: image_uri missing in $META"; exit 1
          fi
          echo "Using IMAGE_URI=$IMAGE_URI"
          echo "##vso[task.setvariable variable=IMAGE_URI]$IMAGE_URI"
        displayName: 'Read container image URI'

      # Deploy container to the Linux Web App (built-in task)
      - task: AzureWebAppContainer@1
        displayName: 'Point Web App to ACR image'
        inputs:
          azureSubscription: '$(serviceConnection)'
          appName: '$(WEB_NAME)'
          containers: '$(IMAGE_URI)'

      # Deploy the Python Azure Function zip (built-in task)
      - task: AzureFunctionApp@2
        displayName: 'Deploy Python Function (run-from-package)'
        inputs:
          connectedServiceNameARM: '$(serviceConnection)'
          appType: 'functionAppLinux'
          appName: '$(FUNC_NAME)'
          package: '$(Pipeline.Workspace)/function/function.zip'
          deploymentMethod: 'runFromPackage'

  # - job: destroy_all_dev
  #   displayName: 'Destroy all infra (dev)'
  #   pool: { name: 'ubuntuvm' }
  #   strategy:
  #     matrix:
  #       dev: { env: dev }
  #   steps:
  #     - checkout: self
  #       clean: true

  #     - task: AzureCLI@2
  #       displayName: "Destroy $(env)"
  #       inputs:
  #         azureSubscription: '$(serviceConnection)'
  #         scriptType: bash
  #         scriptLocation: inlineScript
  #         inlineScript: |
  #           set -euo pipefail
  #           terraform -chdir="$(Build.SourcesDirectory)/terraform" init -input=false
  #           terraform -chdir="$(Build.SourcesDirectory)/terraform" workspace select -or-create "$(env)"
  #           terraform -chdir="$(Build.SourcesDirectory)/terraform" destroy -no-color -auto-approve -var="workflow=$(env)"
